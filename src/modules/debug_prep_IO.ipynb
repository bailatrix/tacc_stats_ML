{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System dependencies\n",
    "from os import listdir\n",
    "import time as clock\n",
    "from datetime import timedelta\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom data handling methods\n",
    "import prep_IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of pre-determined lustre failed jobs\n",
    "src = './lustre_fail_set.txt'\n",
    "\n",
    "# location of search contents\n",
    "acct_base = '/oasis/projects/nsf/sys200/stats/xsede_stats/comet_accounting/'\n",
    "\n",
    "# system data locations\n",
    "acct_info_locs = prep_IO.acct_info_locs\n",
    "arc_data = prep_IO.arc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunks = prep_IO.open_txt(src)\n",
    "#chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# up to error:\n",
    "chosen = [('comet-14-72,comet-19-19,comet-28-55', '2020-05-13T02:11:38', '2020-05-13T05:07:34', '33301074'),\n",
    "         ('comet-30-10', '2020-05-13T10:50:08', '2020-05-13T10:50:12', '33321014'),\n",
    "          ('comet-06-46,comet-12-52,comet-22-[39,64]', '2020-05-12T06:40:43', '2020-05-13T14:27:44', '33283100'),\n",
    "          ('comet-21-07', '2020-05-27T08:49:26', '2020-05-28T01:27:49', '33637231'),\n",
    "          ('comet-22-48', '2020-05-27T09:32:35', '2020-05-28T00:25:06', '33637422'),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to debug\n",
    "def check_len ( df, num ):\n",
    "    return len(df.columns.values.tolist()) > num\n",
    "\n",
    "def purge_str ( df ):\n",
    "    for row,col in df.iterrows():\n",
    "        for i in range(len(col.values)):\n",
    "            val = col.values[i]\n",
    "            time = col.index[i]\n",
    "            \n",
    "            # certain numeric responses are recorded as str\n",
    "            if type(val) is str:\n",
    "                try:\n",
    "                    df.at[row,time] = np.float64( val )\n",
    "                except:\n",
    "                    df.at[row,time] = np.float64(0)\n",
    "                else:\n",
    "                    df.at[row,time] = np.float64(0)\n",
    "                    \n",
    "    return df\n",
    "    \n",
    "def get_host_id ( file_name ):\n",
    "    host,jobid = file_name.split('_')\n",
    "    return host[:11] , jobid[:7]\n",
    "\n",
    "def get_dfs ( file_list, min_jobs, min_cycles=0 ):\n",
    "    job_dfs = {}\n",
    "    count = 0\n",
    "    \n",
    "    for i in range( len(file_list) ):\n",
    "        \n",
    "        if count < min_jobs:\n",
    "            job_file = file_list[i]\n",
    "            df = purge_str( pd.read_csv( source_dir+job_file, index_col=[0,1,2], low_memory=False ) )\n",
    "            host,jobid = get_host_id( job_file )\n",
    "        \n",
    "            if check_len( df, min_cycles ):\n",
    "                job_dfs[jobid] = {}\n",
    "                job_dfs[jobid][host] = df\n",
    "            else:\n",
    "                next\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "    return job_dfs\n",
    "        \n",
    "def sort_hosts ( file_list ):\n",
    "    hosts = {}\n",
    "    \n",
    "    for job_file in file_list:\n",
    "        host,jobid = job_file.split('_')\n",
    "        \n",
    "        if host in hosts:\n",
    "            hosts[host].append( jobid[:7] )\n",
    "        else:\n",
    "            hosts[host] = [ jobid[:7] ]\n",
    "            \n",
    "    return hosts\n",
    "            \n",
    "def sort_jobs ( file_list, job_dfs ):\n",
    "    jobs = {}\n",
    "    \n",
    "    for job_file in file_list:\n",
    "        host,jobid = get_id( job_file )\n",
    "        \n",
    "        if jobid in job_dfs.keys():\n",
    "            if jobid in jobs:\n",
    "                jobs[jobid].append( host )\n",
    "            else:\n",
    "                jobs[jobid] = [ host ]\n",
    "            \n",
    "    return jobs, multiple_hosts(jobs)\n",
    "\n",
    "def multiple_hosts ( jobs_dict ):\n",
    "    return any( len(host) > 1 for job,host in jobs_dict.items() )\n",
    "\n",
    "def cpicore_simple ( job_df, monitor=False ):\n",
    "    data = job_df.loc['intel_hsw']\n",
    "    times = job_df.columns.tolist()\n",
    "    cpicore_list = []\n",
    "    \n",
    "    for i in range(1, len(times)):\n",
    "        chunk = data[times[:i+1]]\n",
    "        devices = { row : np.mean(col.values) for row,col in chunk.iterrows() }\n",
    "        avg_c = { key[0]:0 for key,val in devices.items() }\n",
    "        sum_avgs = 0\n",
    "        \n",
    "        for key,val in avg_c.items():\n",
    "            avg_c[ key ] = devices[ (key, 'CLOCKS_UNHALTED_CORE') ] / devices[ (key, 'INSTRUCTIONS_RETIRED') ]\n",
    "    \n",
    "        for key,val in avg_c.items():\n",
    "            sum_avgs += val\n",
    "            \n",
    "        cpicore_list.append(sum_avgs/24)\n",
    "    \n",
    "    if monitor:\n",
    "        return cpicore_list\n",
    "    \n",
    "    return sum_avgs/24\n",
    "\n",
    "def cpicore ( job_df, monitor=False ):\n",
    "    data = job_df.loc['intel_hsw']\n",
    "    times = job_df.columns.tolist()\n",
    "    cpicore_dict = OrderedDict( )\n",
    "    \n",
    "    for t in times:\n",
    "        cpicore_dict[t] = 0\n",
    "    \n",
    "    for i in range(1, len(times)):\n",
    "        chunk = data[times[:i+1]]\n",
    "        devices = { row : np.mean(col.values) for row,col in chunk.iterrows() }\n",
    "        avg_c = { key[0]:0 for key,val in devices.items() }\n",
    "        sum_avgs = 0\n",
    "        current = times[i]\n",
    "        \n",
    "        for key,val in avg_c.items():\n",
    "            avg_c[ key ] = devices[ (key, 'CLOCKS_UNHALTED_CORE') ] / devices[ (key, 'INSTRUCTIONS_RETIRED') ]\n",
    "    \n",
    "        for key,val in avg_c.items():\n",
    "            sum_avgs += val\n",
    "            \n",
    "        cpicore_dict[current] = sum_avgs/24\n",
    "    \n",
    "    if monitor:\n",
    "        return cpicore_dict\n",
    "    \n",
    "    return sum_avgs/24\n",
    "\n",
    "def cpiref ( devices_dict ):\n",
    "    avg_d = { key[0]:0 for key,val in devices_dict.items() }\n",
    "    sum_avgs = 0\n",
    "    \n",
    "    for key,val in avg_d.items():\n",
    "        avg_d[ key ] = devices_dict[ (key, 'CLOCKS_UNHALTED_REF') ] / devices_dict[ (key, 'INSTRUCTIONS_RETIRED') ]\n",
    "        \n",
    "    for key,val in avg_d.items():\n",
    "        sum_avgs += val\n",
    "        \n",
    "    return sum_avgs/24\n",
    "\n",
    "#def find_notable( cpi_set ):\n",
    "#    notable = []\n",
    "#    \n",
    "#    for jobid,data_dict in cpi_set.items():\n",
    "#        vals = [ val for val in data_dict.values()[1:] ]\n",
    "#        \n",
    "#        if not all():\n",
    "#            notable.append( jobid )\n",
    "\n",
    "def get_stats( cpi_set, outliers=False ):\n",
    "    data = []\n",
    "    outliers = []\n",
    "    \n",
    "    for jobid,cpi_dict in cpicore_set.items():\n",
    "        for val in cpi_dict.values():\n",
    "            if (val > 0):\n",
    "                data.append(np.float64(val))\n",
    "            else:\n",
    "                outliers.append(val)   \n",
    "                \n",
    "    stats = {\n",
    "        'Max' : max(data),\n",
    "        'Min' : min(data),\n",
    "        'Mean' : np.mean(data),\n",
    "        'Std. Dev' : np.std(data),\n",
    "        'Count' : len(data),\n",
    "        'Excluded' : len(outliers)\n",
    "    }\n",
    "    \n",
    "    if outliers:\n",
    "        return stats,outliers\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_out = prep_IO.search( mode='l', from_list=chosen )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(search_out.keys())[1:]\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key = keys[0]\n",
    "sample = search_out[ sample_key ]\n",
    "print( sample_key )\n",
    "print( sample.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"Source Files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Acct Info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Host Info'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Host Info'][\"Specs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Host Info'][\"Timely Data\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
