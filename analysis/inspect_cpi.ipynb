{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle file dependencies\n",
    "from tacc_stats.pickler.job_stats import Job\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System dependencies\n",
    "from os import listdir\n",
    "import time as clock\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of all pickled jobs via comet\n",
    "# new_dir = '/oasis/projects/nsf/sys200/stats/xsede_stats/archive'\n",
    "source_dir = '/oasis/projects/nsf/sys200/tcooper/xsede_stats/comet_pickles/'\n",
    "\n",
    "# Directory to save to\n",
    "save_dir = '../modules/data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of date directories in source_dir\n",
    "dates_list = [ date for date in listdir(source_dir) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dates_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in jobs from cleaned jobs directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_target( date_file ):\n",
    "    jobs_list = []\n",
    "    \n",
    "    # open file and read the content in a list\n",
    "    with open(date_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "        for jobid in lines:\n",
    "            current = jobid[:-1]\n",
    "            jobs_list.append(current)\n",
    "    \n",
    "    return jobs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access and open pickled job files\n",
    "**Process:**\n",
    "    - Iterate through the non-empty date folders available in source_dir\n",
    "    - A file is saved in valid_jobs if:\n",
    "        * The pickled file is a Job object\n",
    "    - Exceptions are skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last compiled 3/16/20\n",
    "pull_dates = dates_list[35:40]\n",
    "n = float(sum([len(listdir(source_dir+date)) for date in pull_dates]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 63614 of 63614.0 files \t (100.0% of total files)\n",
      "\n",
      "Run time: 379.5s\n"
     ]
    }
   ],
   "source": [
    "job_objects = []\n",
    "t0 = clock.time()\n",
    "total = 0\n",
    "\n",
    "for date in pull_dates:  \n",
    "    for jobid in listdir(source_dir+date):\n",
    "        total += 1\n",
    "        clear_output(wait=True)\n",
    "        print(\"Processing file {} of {} files \\t ({}% of total files)\".format(total, n, np.round( total/n*100, 2)))\n",
    "        \n",
    "        try:\n",
    "            pickle_file = open( source_dir+date+'/'+jobid, 'rb')\n",
    "            job_file = pickle.load(pickle_file)\n",
    "            job_objects.append(job_file)\n",
    "            pickle_file.close()\n",
    "        except:\n",
    "            next\n",
    "            \n",
    "        t2 = clock.time()\n",
    "        print\n",
    "        print(\"Run time: {}s\".format(np.round(t2-t0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6062"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_val( val ):\n",
    "    try:\n",
    "        val = float(val)\n",
    "        return val\n",
    "    except:\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def convert_dt( val ):\n",
    "    return dt.datetime.utcfromtimestamp( val ).strftime( \"%Y-%m-%d %H:%M:%S\" )\n",
    "\n",
    "def get_schemas( job ):\n",
    "    return { stat:schema.keys() for stat,schema in job.schemas.items() }\n",
    "\n",
    "def get_indices( job, host ):\n",
    "    indices = []\n",
    "    stats = [ stat for stat in job.schemas.keys() if stat in host.stats.keys() ]\n",
    "    schemas = { stat:schema.keys() for stat,schema in job.schemas.items() }\n",
    "    cores = { stat:core.keys() for stat,core in host.stats.items() }\n",
    "    \n",
    "    for stat in stats:\n",
    "        for core in cores[stat]:\n",
    "            for schema in schemas[stat]:\n",
    "                indices.append( (stat,core,schema) )\n",
    "             \n",
    "    return indices\n",
    "\n",
    "def get_times( job, host ):\n",
    "    times = [ job.start_time ]\n",
    "    times.extend( host.times )\n",
    "    times.append( job.end_time )\n",
    "    return [ convert_dt(t) for t in times ]\n",
    "\n",
    "def clean_list( data_list ):\n",
    "    return [ check_val( x ) for x in data_list ]\n",
    "    \n",
    "def get_data( host, row_labels ):\n",
    "    data = { label:[] for label in row_labels }\n",
    "    \n",
    "    for stat,node in host.stats.items():\n",
    "        for core,matrix in node.items():\n",
    "            matrix = matrix.T\n",
    "            for i in range(len(matrix)):\n",
    "                data[stat,core] = clean_list( matrix[i] )\n",
    "    return data\n",
    "\n",
    "def fill_df( template_df, data_dict):\n",
    "    for row,data in data_dict.items():\n",
    "        template_df.loc[row].update( pd.Series(data) )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs( job_dfs, job_objects ):\n",
    "    job_df_pairs = []\n",
    "    wanted = job_dfs.keys()\n",
    "    \n",
    "    for idx in range(len(job_objects)):\n",
    "        job = job_objects[idx]\n",
    "        jobid = job.id\n",
    "        \n",
    "        if (jobid in wanted) and (len(job.times) > 8) and (len(job.hosts.keys()) == 1):\n",
    "            job_df_pairs.append( (job, job_dfs[jobid]) )\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return job_df_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def find_next( current, unsorted ):\n",
    "#    target = current + 00:10:00\n",
    "#    found = unsorted[0]\n",
    "#    proximity = target - found\n",
    "#    \n",
    "#    if len(unsorted) > 1:\n",
    "#        for i in range(len(unsorted)):\n",
    "#            if target - unsorted[i] < proximity:\n",
    "#                found = unsorted[i]\n",
    "#                proximity = target - found\n",
    "#    return found\n",
    "#\n",
    "#def fill_sorted( start, unsorted ):\n",
    "#    sorted_list = []\n",
    "#    \n",
    "#    for i in range(len(unsorted)):\n",
    "#        current = sorted_list[i]\n",
    "#        next_time = find_next( current, unsorted )\n",
    "#        sorted_list[i+1] = next_time\n",
    "#        \n",
    "#def sort_times( job ):\n",
    "#    start = job.start\n",
    "#    mid = job.times\n",
    "#    end = job.end\n",
    "#    \n",
    "#    if start == end:\n",
    "#        return [start]\n",
    "#    elif len(mid) < 1:\n",
    "#        return [start, end]\n",
    "#    elif len(mid) < 2:\n",
    "#        return [start, mid[0], end]\n",
    "#    else:\n",
    "#        return fill_sorted( start, mid.append(end) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loops in loops in loops (Cleaning data)\n",
    "**Notes:**\n",
    "    - If a value is missing from the data, it will be replaced with '0' for the purpose of this project\n",
    "    - If a type of statistic was not collected on the job, that column is dropped from the DataFrame\n",
    "    - Two files are created during each iteration:\n",
    "         1) A .csv of the descriptive statistics for that host,job pair\n",
    "         2) A full .csv of the host,job data from the formatted DataFrame\n",
    "    - Naming convention: Files are labelled as '{host}_{jobid}' to support random lookup\n",
    "         * A job run on multiple host nodes is processed and saved with each individual host,job pair *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = float(sum([len(job.hosts.keys()) for job in job_objects]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Jobs (this date):\t\t6062\n",
      "Total Host,Job Pairs:\t\t6264\n",
      "------------------------------------\n",
      "Remaining jobs to scan:\t\t6062\n"
     ]
    }
   ],
   "source": [
    "cut = len(job_objects)/2\n",
    "first = 0 # 2025\n",
    "stop = len(job_objects)\n",
    "rem = stop - first\n",
    "\n",
    "print \"Total Jobs (this date):\\t\\t\", len(job_objects)\n",
    "print \"Total Host,Job Pairs:\\t\\t\", int(m)\n",
    "print(\"------------------------------------\")\n",
    "print \"Remaining jobs to scan:\\t\\t\", int(rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hosts for job 6062 of 6062 \t (99.98% of total)\n"
     ]
    }
   ],
   "source": [
    "job_dfs = {}\n",
    "t0 = clock.time()\n",
    "total = 0\n",
    "current = 0\n",
    "\n",
    "for job_idx in range( first, stop ):\n",
    "    job = job_objects[ job_idx ]\n",
    "    schemas = get_schemas( job )\n",
    "    total += 1\n",
    "    \n",
    "    # support for tracking progress in below print statements\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # iterate through each host object job was run on\n",
    "    for host_name, host in job.hosts.iteritems():\n",
    "        print(\"Processing hosts for job {} of {} \\t ({}% of total)\".format(job_idx+1, stop, np.round( (current+first)/m*100, 2)))\n",
    "        current += 1\n",
    "        \n",
    "        # build MultiIndex for df \n",
    "        idx_labels = get_indices( job, host )\n",
    "        indices = pd.MultiIndex.from_tuples( idx_labels, names=['Stat', 'Device', 'Schema'] )\n",
    "                    \n",
    "        # process timestamps\n",
    "        times = get_times( job, host )\n",
    "    \n",
    "        # collect job data\n",
    "        data = get_data( host, idx_labels )\n",
    "        \n",
    "        # create df with MultiIndex, ordered times\n",
    "        df = pd.DataFrame( index=indices, columns=times ).sort_index()\n",
    "        \n",
    "        # fill df\n",
    "        for stat,devices in host.stats.items():\n",
    "            for device,cycles in devices.items():\n",
    "                for i in range(len(cycles)):\n",
    "                    for j in range(len(cycles[i])):\n",
    "                        try:\n",
    "                            schema = schemas[stat][j]\n",
    "                            df.loc[(stat,device,schema)] = check_val(cycles[i][j])\n",
    "                        except:\n",
    "                            next\n",
    "        \n",
    "        # save job info from DataFrame to csv file\n",
    "        #df.to_csv( path_or_buf=save_dir+\"{}_{}.csv\".format( host_name, job.id ) )\n",
    "        job_dfs[job.id] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# check that no job was missed\n",
    "if total == ( stop-first ):\n",
    "    print \"Success!\"\n",
    "else:\n",
    "    print stop - first - total, \"jobs missing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in CPICORE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_len ( df, num ):\n",
    "    return len(df.columns.values.tolist()) > num\n",
    "\n",
    "def purge_str ( df ):\n",
    "    for row,col in df.iterrows():\n",
    "        for i in range(len(col.values)):\n",
    "            val = col.values[i]\n",
    "            time = col.index[i]\n",
    "            \n",
    "            # certain numeric responses are recorded as str\n",
    "            if type(val) is str:\n",
    "                try:\n",
    "                    df.at[row,time] = np.float64( val )\n",
    "                except:\n",
    "                    df.at[row,time] = np.float64(0)\n",
    "                else:\n",
    "                    df.at[row,time] = np.float64(0)\n",
    "                    \n",
    "    return df\n",
    "\n",
    "def get_id ( file_name ):\n",
    "    host,jobid = file_name.split('_')\n",
    "    return host[:11] , jobid[:7]\n",
    "\n",
    "def get_dfs ( file_list, min_jobs, min_cycles=0 ):\n",
    "    job_dfs = {}\n",
    "    count = 0\n",
    "    \n",
    "    for i in range( len(file_list) ):\n",
    "        \n",
    "        if count < min_jobs:\n",
    "            job_file = file_list[i]\n",
    "            df = purge_str( pd.read_csv( source_dir+job_file, index_col=[0,1,2], low_memory=False ) )\n",
    "            host,jobid = get_id( job_file )\n",
    "        \n",
    "            if check_len( df, min_cycles ):\n",
    "                job_dfs[jobid] = df\n",
    "            else:\n",
    "                next\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "    return job_dfs\n",
    "        \n",
    "def sort_hosts ( file_list ):\n",
    "    hosts = {}\n",
    "    \n",
    "    for job_file in file_list:\n",
    "        host,jobid = job_file.split('_')\n",
    "        \n",
    "        if host in hosts:\n",
    "            hosts[host].append( jobid[:7] )\n",
    "        else:\n",
    "            hosts[host] = [ jobid[:7] ]\n",
    "            \n",
    "    return hosts\n",
    "            \n",
    "def sort_jobs ( file_list, job_dfs ):\n",
    "    jobs = {}\n",
    "    \n",
    "    for job_file in file_list:\n",
    "        host,jobid = get_id( job_file )\n",
    "        \n",
    "        if jobid in job_dfs.keys():\n",
    "            if jobid in jobs:\n",
    "                jobs[jobid].append( host )\n",
    "            else:\n",
    "                jobs[jobid] = [ host ]\n",
    "            \n",
    "    return jobs, multiple_hosts(jobs)\n",
    "\n",
    "def multiple_hosts ( jobs_dict ):\n",
    "    return any( len(host) > 1 for job,host in jobs_dict.items() )\n",
    "\n",
    "def cpicore ( job_df, monitor=False ):\n",
    "    data = job_df.loc['intel_hsw']\n",
    "    times = job_df.columns.tolist()\n",
    "    cpicore_dict = OrderedDict( )\n",
    "    \n",
    "    for t in times:\n",
    "        cpicore_dict[t] = 0\n",
    "    \n",
    "    for i in range(1, len(times)):\n",
    "        chunk = data[times[:i+1]]\n",
    "        devices = { row : np.mean(col.values) for row,col in chunk.iterrows() }\n",
    "        avg_c = { key[0]:0 for key,val in devices.items() }\n",
    "        sum_avgs = 0\n",
    "        current = times[i]\n",
    "        \n",
    "        for key,val in avg_c.items():\n",
    "            avg_c[ key ] = devices[ (key, 'CLOCKS_UNHALTED_CORE') ] / devices[ (key, 'INSTRUCTIONS_RETIRED') ]\n",
    "    \n",
    "        for key,val in avg_c.items():\n",
    "            sum_avgs += val\n",
    "            \n",
    "        cpicore_dict[current] = sum_avgs/24\n",
    "    \n",
    "    if monitor:\n",
    "        return cpicore_dict\n",
    "    \n",
    "    return sum_avgs/24\n",
    "\n",
    "def cpiref ( job_df ):\n",
    "    data = job_df.loc['intel_hsw'] \n",
    "    devices = { row : np.mean(col.values) for row,col in data.iterrows() }\n",
    "    avg_d = { key[0]:0 for key,val in devices.items() }\n",
    "    sum_avgs = 0\n",
    "    \n",
    "    for key,val in avg_d.items():\n",
    "        avg_d[ key ] = devices[ (key, 'CLOCKS_UNHALTED_REF') ] / devices[ (key, 'INSTRUCTIONS_RETIRED') ]\n",
    "        \n",
    "    for key,val in avg_d.items():\n",
    "        sum_avgs += val\n",
    "        \n",
    "    return sum_avgs/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4070662': ('2016-09-16', 'comet-14-66', 1.0002, 1.00081),\n",
       " '4244338': ('2016-09-16', 'comet-27-12', 1.00001, 1.00001),\n",
       " '4244341': ('2016-09-16', 'comet-06-55', 1.00001, 1.0),\n",
       " '4244933': ('2016-09-16', 'comet-25-01', 1.00025, 0.99964),\n",
       " '4255235': ('2016-09-16', 'comet-13-48', 1.00077, 1.00215),\n",
       " '4255874': ('2016-09-15', 'comet-06-02', 1.64812, 1.44424),\n",
       " '4256084': ('2016-09-16', 'comet-06-42', 1.9496, 1.76934),\n",
       " '4256234': ('2016-09-15', 'comet-06-08', 1.59796, 1.40492),\n",
       " '4256386': ('2016-09-17', 'comet-10-64', 1.0001, 1.00042),\n",
       " '4262035': ('2016-09-16', 'comet-20-10', 3.43046, 2.95714),\n",
       " '4262682': ('2016-09-17', 'comet-07-11', 1.00017, 1.00073),\n",
       " '4262823': ('2016-09-16', 'comet-07-05', 1.00023, 1.00018),\n",
       " '4263608': ('2016-09-16', 'comet-10-60', 1.92217, 1.51549),\n",
       " '4263622': ('2016-09-16', 'comet-20-53', 1.69925, 3.54011),\n",
       " '4264410': ('2016-09-16', 'comet-26-71', 1.00001, 1.00001),\n",
       " '4264648': ('2016-09-16', 'comet-06-38', 1.0014, 1.00121),\n",
       " '4264832': ('2016-09-16', 'comet-28-62', 3.14615, 2.75892),\n",
       " '4265800': ('2016-09-16', 'comet-06-08', 1.80786, 1.61594),\n",
       " '4266311': ('2016-09-16', 'comet-10-60', 2.09053, 1.78203),\n",
       " '4267775': ('2016-09-16', 'comet-02-01', 1.61851, 1.44747),\n",
       " '4267852': ('2016-09-16', 'comet-06-02', 1.66708, 1.47292),\n",
       " '4267889': ('2016-09-16', 'comet-06-08', 1.60974, 1.43721),\n",
       " '4267894': ('2016-09-16', 'comet-06-16', 1.67141, 1.50258),\n",
       " '4267969': ('2016-09-16', 'comet-06-37', 1.55672, 1.38988),\n",
       " '4267991': ('2016-09-16', 'comet-02-01', 1.62847, 1.45648),\n",
       " '4268096': ('2016-09-16', 'comet-02-02', 2.33509, 2.06117),\n",
       " '4268123': ('2016-09-16', 'comet-06-16', 1.00011, 1.00008),\n",
       " '4268191': ('2016-09-16', 'comet-06-37', 1.562, 1.39457),\n",
       " '4268405': ('2016-09-16', 'comet-06-37', 1.00001, 1.00001),\n",
       " '4268423': ('2016-09-16', 'comet-06-08', 1.55266, 1.38627),\n",
       " '4268431': ('2016-09-16', 'comet-06-61', 1.74832, 1.56108),\n",
       " '4268612': ('2016-09-17', 'comet-04-09', 1.00031, 1.00022),\n",
       " '4268858': ('2016-09-16', 'comet-06-15', 2.23936, 1.96272),\n",
       " '4268895': ('2016-09-16', 'comet-06-37', 1.49375, 1.33363),\n",
       " '4268913': ('2016-09-16', 'comet-06-16', 1.59554, 1.42915),\n",
       " '4268942': ('2016-09-16', 'comet-06-51', 1.53177, 1.36765),\n",
       " '4268956': ('2016-09-17', 'comet-06-02', 1.53099, 1.36688),\n",
       " '4268987': ('2016-09-17', 'comet-04-13', 1.43203, 1.27852),\n",
       " '4269017': ('2016-09-17', 'comet-06-42', 1.55303, 1.39596),\n",
       " '4269156': ('2016-09-17', 'comet-06-37', 1.50412, 1.34287),\n",
       " '4269172': ('2016-09-17', 'comet-06-51', 1.53383, 1.36937),\n",
       " '4269203': ('2016-09-17', 'comet-06-05', 2.26243, 1.98132),\n",
       " '4269452': ('2016-09-17', 'comet-06-06', 2.278, 1.99527),\n",
       " '4271019': ('2016-09-16', 'comet-20-61', 2.50624, 3.1972),\n",
       " '4271148': ('2016-09-16', 'comet-14-66', 1.82486, 3.80166),\n",
       " '4271273': ('2016-09-16', 'comet-07-05', 1.53634, 1.31287),\n",
       " '4271293': ('2016-09-16', 'comet-04-09', 2.46565, 2.11473),\n",
       " '4271390': ('2016-09-16', 'comet-13-45', 1.00834, 2.10087),\n",
       " '4271399': ('2016-09-16', 'comet-13-45', 2.2924, 4.77581),\n",
       " '4271428': ('2016-09-16', 'comet-27-12', 1.80056, 1.5611),\n",
       " '4273037': ('2016-09-16', 'comet-06-53', 1.00005, 1.00023),\n",
       " '4273219': ('2016-09-16', 'comet-06-42', 1.0, 1.00001),\n",
       " '4273617': ('2016-09-16', 'comet-13-46', 1.16327, 2.42331),\n",
       " '4273933': ('2016-09-16', 'comet-28-62', 1.87677, 1.80647),\n",
       " '4274113': ('2016-09-16', 'comet-06-42', 1.84873, 1.59344),\n",
       " '4275046': ('2016-09-16', 'comet-20-51', 1.89899, 1.80629),\n",
       " '4276807': ('2016-09-16', 'comet-28-62', 1.0938, 1.08369),\n",
       " '4276809': ('2016-09-16', 'comet-13-48', 1.87028, 3.89645),\n",
       " '4276820': ('2016-09-16', 'comet-28-55', 2.88449, 2.74153),\n",
       " '4276839': ('2016-09-16', 'comet-07-24', 9.14296, 8.12847),\n",
       " '4277001': ('2016-09-17', 'comet-14-66', 1.00051, 1.00136),\n",
       " '4277524': ('2016-09-17', 'comet-06-55', 1.45597, 1.30255),\n",
       " '4277535': ('2016-09-17', 'comet-07-11', 1.69554, 3.53233),\n",
       " '4277654': ('2016-09-17', 'comet-04-27', 1.44383, 1.28909),\n",
       " '4277726': ('2016-09-17', 'comet-10-62', 1.00002, 1.0001),\n",
       " '4278147': ('2016-09-17', 'comet-06-20', 2.06993, 1.81099),\n",
       " '4278150': ('2016-09-17', 'comet-06-56', 2.10496, 1.81565),\n",
       " '4278231': ('2016-09-17', 'comet-10-62', 1.51882, 3.16403),\n",
       " '4278537': ('2016-09-17', 'comet-10-57', 1.57491, 1.42678),\n",
       " '5866884': ('2016-11-16', 'comet-06-08', 1.64459, 1.46843),\n",
       " '5870724': ('2016-11-17', 'comet-02-35', 1.26001, 1.23175),\n",
       " '5870782': ('2016-11-17', 'comet-13-06', 1.13953, 1.12796),\n",
       " '5872705': ('2016-11-17', 'comet-14-22', 0.99981, 0.99822),\n",
       " '5872710': ('2016-11-17', 'comet-02-05', 0.99867, 0.99701),\n",
       " '5875045': ('2016-11-17', 'comet-02-64', 1.0018, 1.00155),\n",
       " '5875536': ('2016-11-17', 'comet-04-49', 1.01913, 1.01571),\n",
       " '5875593': ('2016-11-17', 'comet-14-72', 1.00028, 1.00026),\n",
       " '5875686': ('2016-11-17', 'comet-06-35', 1.00055, 1.00027),\n",
       " '5875687': ('2016-11-17', 'comet-06-37', 1.00056, 1.00025),\n",
       " '5875689': ('2016-11-17', 'comet-02-31', 1.33635, 1.16194),\n",
       " '5875690': ('2016-11-17', 'comet-16-49', 1.29531, 1.12658),\n",
       " '5875703': ('2016-11-17', 'comet-06-12', 1.20959, 1.04295),\n",
       " '5875704': ('2016-11-17', 'comet-15-25', 1.28167, 1.10809),\n",
       " '5875708': ('2016-11-17', 'comet-04-46', 1.25408, 1.08123),\n",
       " '5875710': ('2016-11-17', 'comet-06-19', 1.22025, 1.05192),\n",
       " '5875723': ('2016-11-17', 'comet-04-15', 1.23854, 1.0677),\n",
       " '5875724': ('2016-11-17', 'comet-13-20', 1.18845, 1.02495),\n",
       " '5875726': ('2016-11-17', 'comet-13-34', 1.23922, 1.06825),\n",
       " '5875727': ('2016-11-17', 'comet-06-12', 1.28681, 1.10937),\n",
       " '5875728': ('2016-11-17', 'comet-13-37', 1.23285, 1.06287),\n",
       " '5875729': ('2016-11-17', 'comet-05-23', 1.26302, 1.09911),\n",
       " '5875730': ('2016-11-17', 'comet-02-03', 1.27265, 1.10071),\n",
       " '5875731': ('2016-11-17', 'comet-02-26', 1.22781, 2.55793),\n",
       " '5875732': ('2016-11-17', 'comet-02-28', 1.22987, 1.06832),\n",
       " '5875733': ('2016-11-17', 'comet-02-32', 1.24234, 1.09305),\n",
       " '5875734': ('2016-11-17', 'comet-02-41', 1.21905, 1.05089),\n",
       " '5875735': ('2016-11-17', 'comet-02-57', 1.26084, 1.09276),\n",
       " '5875736': ('2016-11-17', 'comet-02-38', 1.24575, 1.07389),\n",
       " '5875737': ('2016-11-17', 'comet-02-59', 1.21143, 1.04433),\n",
       " '5875738': ('2016-11-17', 'comet-06-37', 1.25074, 1.07821),\n",
       " '5875739': ('2016-11-17', 'comet-13-40', 1.23892, 1.06833),\n",
       " '5875740': ('2016-11-17', 'comet-02-05', 1.23441, 1.0646),\n",
       " '5875741': ('2016-11-17', 'comet-13-51', 1.23869, 1.06807),\n",
       " '5875742': ('2016-11-17', 'comet-04-13', 1.18057, 1.0177),\n",
       " '5875747': ('2016-11-17', 'comet-04-15', 1.23947, 1.0685),\n",
       " '5875748': ('2016-11-17', 'comet-04-21', 1.21871, 1.05877),\n",
       " '5875749': ('2016-11-17', 'comet-04-40', 1.22227, 1.05365),\n",
       " '5875755': ('2016-11-17', 'comet-16-49', 1.19558, 1.03631),\n",
       " '5875756': ('2016-11-17', 'comet-16-50', 1.26582, 1.09664),\n",
       " '5875765': ('2016-11-17', 'comet-16-67', 1.2388, 1.07177),\n",
       " '5875776': ('2016-11-17', 'comet-02-05', 1.19918, 1.03402),\n",
       " '5875777': ('2016-11-17', 'comet-02-15', 1.21296, 1.04775),\n",
       " '5875779': ('2016-11-17', 'comet-02-40', 1.22984, 1.06018),\n",
       " '5875780': ('2016-11-17', 'comet-02-44', 1.26501, 1.10082),\n",
       " '5875781': ('2016-11-17', 'comet-02-56', 1.22735, 1.06126),\n",
       " '5875782': ('2016-11-17', 'comet-02-64', 1.18897, 1.03443),\n",
       " '5875796': ('2016-11-17', 'comet-16-15', 1.20245, 1.04532),\n",
       " '5875835': ('2016-11-17', 'comet-04-35', 1.24747, 1.08686),\n",
       " '5875839': ('2016-11-17', 'comet-05-23', 1.24403, 1.08063),\n",
       " '5875848': ('2016-11-17', 'comet-04-13', 1.21315, 1.0458),\n",
       " '5875849': ('2016-11-17', 'comet-04-15', 1.23996, 1.06889),\n",
       " '5875850': ('2016-11-17', 'comet-04-40', 1.23246, 1.06244),\n",
       " '5875851': ('2016-11-17', 'comet-04-65', 1.22958, 1.05995),\n",
       " '5875852': ('2016-11-17', 'comet-02-03', 1.24049, 1.06951),\n",
       " '5875854': ('2016-11-17', 'comet-02-28', 1.17299, 1.01267),\n",
       " '5875855': ('2016-11-17', 'comet-02-32', 1.24572, 1.09385),\n",
       " '5875856': ('2016-11-17', 'comet-02-41', 1.20282, 1.03691),\n",
       " '5875857': ('2016-11-17', 'comet-02-57', 1.24929, 1.07811),\n",
       " '5875859': ('2016-11-17', 'comet-02-59', 1.18829, 1.02437),\n",
       " '5875871': ('2016-11-17', 'comet-13-17', 1.17129, 1.00989),\n",
       " '5875900': ('2016-11-17', 'comet-02-31', 1.26073, 1.08921),\n",
       " '5875911': ('2016-11-17', 'comet-06-37', 1.24554, 1.0737),\n",
       " '5875923': ('2016-11-17', 'comet-14-72', 1.22243, 1.06462),\n",
       " '5875956': ('2016-11-17', 'comet-13-01', 1.19429, 1.02952),\n",
       " '5875960': ('2016-11-17', 'comet-02-40', 1.24205, 1.07064),\n",
       " '5875961': ('2016-11-17', 'comet-02-45', 1.31013, 1.13222),\n",
       " '5875971': ('2016-11-17', 'comet-04-13', 1.19949, 1.03347),\n",
       " '5875972': ('2016-11-17', 'comet-04-15', 1.2235, 1.05426),\n",
       " '5876026': ('2016-11-17', 'comet-02-36', 1.34305, 1.16483),\n",
       " '5876083': ('2016-11-17', 'comet-02-50', 1.2852, 1.10816),\n",
       " '5876084': ('2016-11-17', 'comet-05-23', 1.29519, 1.12858),\n",
       " '5876085': ('2016-11-17', 'comet-16-49', 1.1812, 1.02577),\n",
       " '5876088': ('2016-11-17', 'comet-06-12', 1.28671, 1.10929),\n",
       " '5876089': ('2016-11-17', 'comet-06-19', 1.26831, 1.09337),\n",
       " '5876090': ('2016-11-17', 'comet-06-32', 1.31134, 1.13044),\n",
       " '5876122': ('2016-11-17', 'comet-14-72', 1.28281, 1.13837),\n",
       " '5876131': ('2016-11-17', 'comet-02-40', 1.27825, 1.10191),\n",
       " '5876132': ('2016-11-17', 'comet-05-63', 1.28917, 1.11133),\n",
       " '5876133': ('2016-11-17', 'comet-02-56', 1.28159, 1.11427),\n",
       " '5876186': ('2016-11-17', 'comet-02-44', 1.26398, 1.0984),\n",
       " '5876187': ('2016-11-17', 'comet-02-64', 1.19702, 1.04339),\n",
       " '5884525': ('2016-11-16', 'comet-08-13', 1.62541, 1.4001),\n",
       " '5884606': ('2016-11-16', 'comet-05-64', 1.97514, 4.11489),\n",
       " '5892621': ('2016-11-17', 'comet-11-07', 1.02812, 1.02309),\n",
       " '5892630': ('2016-11-17', 'comet-13-69', 1.04515, 1.03683),\n",
       " '5893319': ('2016-11-16', 'comet-08-03', 1.12425, 0.9692),\n",
       " '5893488': ('2016-11-17', 'comet-11-01', 7.93722, 6.8285),\n",
       " '5893489': ('2016-11-17', 'comet-02-53', 1.00277, 1.00226),\n",
       " '5893490': ('2016-11-17', 'comet-02-56', 8.75228, 7.53216),\n",
       " '5893491': ('2016-11-17', 'comet-13-40', 1.00287, 1.00233),\n",
       " '5893805': ('2016-11-16', 'comet-02-36', 1.00002, 1.0),\n",
       " '5893806': ('2016-11-16', 'comet-02-72', 1.58734, 1.37281),\n",
       " '5896177': ('2016-11-17', 'comet-05-49', 1.00397, 1.00258),\n",
       " '5896824': ('2016-11-17', 'comet-02-47', 1.89736, 1.69626),\n",
       " '5897359': ('2016-11-17', 'comet-02-42', 1.61532, 1.44238),\n",
       " '5897406': ('2016-11-17', 'comet-02-23', 1.00271, 1.00157),\n",
       " '5898561': ('2016-11-17', 'comet-15-29', 1.00006, 1.00008),\n",
       " '5903355': ('2016-11-17', 'comet-16-03', 1.01107, 1.00998),\n",
       " '5906438': ('2016-11-17', 'comet-30-15', 0.99925, 0.9985),\n",
       " '5908157': ('2016-11-17', 'comet-04-45', 2.04465, 1.74495),\n",
       " '5908183': ('2016-11-17', 'comet-05-65', 1.00023, 1.00016),\n",
       " '5908619': ('2016-11-17', 'comet-13-38', 2.09367, 1.78738),\n",
       " '5908624': ('2016-11-17', 'comet-13-39', 1.00027, 1.00019),\n",
       " '5908995': ('2016-11-17', 'comet-02-65', 1.78867, 1.59709),\n",
       " '5909507': ('2016-11-17', 'comet-30-16', 4.36408, 3.38275),\n",
       " '5909514': ('2016-11-17', 'comet-15-26', 3.46961, 3.06092),\n",
       " '5910611': ('2016-11-17', 'comet-31-07', 0.99805, 0.99711),\n",
       " '5912864': ('2016-11-17', 'comet-08-13', 1.43048, 1.23218),\n",
       " '5914159': ('2016-11-17', 'comet-02-65', 1.51744, 1.35498),\n",
       " '5914577': ('2016-11-17', 'comet-13-17', 3.69516, 3.25367),\n",
       " '5915411': ('2016-11-17', 'comet-06-19', 1.00088, 1.00065),\n",
       " '5915418': ('2016-11-17', 'comet-08-17', 3.54511, 3.15455),\n",
       " '5917120': ('2016-11-17', 'comet-08-13', 1.44541, 1.24523),\n",
       " '5917430': ('2016-11-17', 'comet-08-17', 1.00139, 1.00115),\n",
       " '5918879': ('2016-11-17', 'comet-08-06', 1.51037, 1.32507),\n",
       " '5918904': ('2016-11-17', 'comet-08-07', 1.00066, 1.00045),\n",
       " '5921436': ('2016-11-17', 'comet-05-02', 2.12076, 2.07726),\n",
       " '5925293': ('2016-11-17', 'comet-08-30', 2.1133, 4.40271),\n",
       " '5925335': ('2016-11-17', 'comet-08-13', 1.42102, 1.2338),\n",
       " '5925971': ('2016-11-17', 'comet-02-22', 2.86826, 2.52182),\n",
       " '5926419': ('2016-11-17', 'comet-02-45', 3.53523, 3.07529),\n",
       " '5926663': ('2016-11-17', 'comet-04-65', 1.76293, 1.51898),\n",
       " '5927081': ('2016-11-17', 'comet-05-49', 1.71844, 1.5345),\n",
       " '5927381': ('2016-11-17', 'comet-06-67', 1.53213, 1.25156),\n",
       " '5927802': ('2016-11-17', 'comet-05-26', 2.10422, 2.07152),\n",
       " '5928224': ('2016-11-17', 'comet-02-70', 1.65848, 1.49784),\n",
       " '5928467': ('2016-11-17', 'comet-02-10', 1.80945, 1.57536),\n",
       " '5928544': ('2016-11-17', 'comet-02-65', 1.51945, 1.3568),\n",
       " '5928617': ('2016-11-17', 'comet-07-09', 1.76504, 1.57599),\n",
       " '5928994': ('2016-11-17', 'comet-08-56', 3.0379, 2.65963),\n",
       " '5929136': ('2016-11-17', 'comet-08-53', 1.81947, 1.59347),\n",
       " '5929985': ('2016-11-17', 'comet-08-28', 1.47934, 1.31037),\n",
       " '5930200': ('2016-11-17', 'comet-08-30', 1.52218, 3.17118),\n",
       " '5930316': ('2016-11-17', 'comet-07-08', 1.67517, 1.49579),\n",
       " '5931299': ('2016-11-17', 'comet-08-60', 2.89584, 2.50545),\n",
       " '5931450': ('2016-11-17', 'comet-08-65', 3.37837, 2.99579),\n",
       " '5931522': ('2016-11-17', 'comet-06-35', 2.17805, 1.91053),\n",
       " '5931559': ('2016-11-17', 'comet-05-49', 1.74914, 1.56191),\n",
       " '5932662': ('2016-11-17', 'comet-08-54', 3.35705, 2.91795),\n",
       " '5932759': ('2016-11-17', 'comet-08-57', 3.18828, 2.79694),\n",
       " '5932789': ('2016-11-17', 'comet-08-48', 2.97869, 2.59424),\n",
       " '5932863': ('2016-11-17', 'comet-08-59', 3.53303, 3.08525),\n",
       " '5933301': ('2016-11-17', 'comet-04-67', 1.97489, 1.70354),\n",
       " '5934007': ('2016-11-17', 'comet-08-59', 2.83691, 2.47922),\n",
       " '5934046': ('2016-11-17', 'comet-02-23', 1.68544, 1.50496),\n",
       " '5934666': ('2016-11-17', 'comet-05-29', 3.22737, 2.79108),\n",
       " '5935130': ('2016-11-17', 'comet-08-41', 2.45913, 2.15572),\n",
       " '5935211': ('2016-11-17', 'comet-08-47', 1.74274, 1.51442),\n",
       " '5935320': ('2016-11-17', 'comet-05-25', 3.2463, 2.80961),\n",
       " '5935996': ('2016-11-17', 'comet-08-13', 1.49039, 1.31719)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_jobs( job_dfs, job_objects )\n",
    "sample_set = {}\n",
    "jobids = job_dfs.keys()\n",
    "\n",
    "for job_tup in data:\n",
    "    job = job_tup[0]\n",
    "    job_data = job_tup[1]\n",
    "    jobid = job.id\n",
    "    date = convert_dt( job.times[-1] )[:10]\n",
    "    host = job.hosts[ job.hosts.keys()[0] ].name\n",
    "    core = np.round( cpicore( job_data ), 5 )\n",
    "    ref = np.round( cpiref( job_data ), 5 )\n",
    "    \n",
    "    sample_set[jobid] = ( date, host, core, ref )\n",
    "\n",
    "sample_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
