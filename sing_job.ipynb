{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file dependencies\n",
    "from tacc_stats.pickler.job_stats import Job\n",
    "import cPickle as pickle\n",
    "import argparse\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle file with job data\n",
    "pickle_file = open('/oasis/projects/nsf/sys200/tcooper/xsede_stats/comet_pickles/2016-08-21/3859912', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-982ac5c2cfbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# open pickle file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# extract job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjobid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpickle_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjobid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# open pickle file\n",
    "# extract job\n",
    "jobid = pickle.load(pickle_file)\n",
    "pickle_file.close()\n",
    "jobid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique hosts\n",
    "hosts = {}\n",
    "for job in jobs:\n",
    "    for host in job.hosts.keys():\n",
    "        hosts[host] = True\n",
    "hosts = hosts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull job details and stats\n",
    "all_jobs = {}\n",
    "\n",
    "# get stats from hosts\n",
    "for host in hosts:\n",
    "    \n",
    "    # compiling host data\n",
    "    host.get_stats_paths\n",
    "    host.read_stats_file_header\n",
    "    host.parse_stats\n",
    "    host.read_stats_file\n",
    "    host.gather_stats\n",
    "    host.get_stats\n",
    "    \n",
    "    if job\n",
    "    # saving data to dict\n",
    "    # key is jobid\n",
    "    all_jobs[host.job.id] = {\n",
    "        \"Host\" : host.name,\n",
    "        \"Start Time\" : pd.to_datetime(round(host.job.start_time), unit='s'),\n",
    "        \"End Time\" : pd.to_datetime(round(host.job.end_time), unit='s'),\n",
    "        \"Cycles Stats Collected\" : len(host.times),\n",
    "        #\"Account\" : host.job.acct,\n",
    "        #\"Times\" : [pd.to_datetime(round(time), unit='s')\n",
    "        #            for time in host.times],\n",
    "    }\n",
    "        \n",
    "        for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear jobs with no stats collected\n",
    "jobs_dict = {job:stats for job,stats in all_jobs.iteritems()\n",
    "             if stats['Cycles Stats Collected'] != 0}\n",
    "jobs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-85cdcc481406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# if stats collected for job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# add job stats from all_stats to jobs_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mjobName\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjobName\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_stats' is not defined"
     ]
    }
   ],
   "source": [
    "# if stats collected for job\n",
    "# add job stats from all_stats to jobs_dict\n",
    "for stat,job in all_stats.iteritems():\n",
    "    for jobName in job.keys():\n",
    "        if jobName in jobs_dict.keys():\n",
    "            print jobName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all data\n",
    "df = pd.DataFrame( stats_dict )\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"index\",\"intel_hsw\",\"ib\",\n",
    "         # \"ib_sw\",\"ib_ext\",\n",
    "        \"llite\",\"lnet\",\n",
    "         #\"mdc\",\"osc\",\n",
    "         \"block\",\"cpu\",\"mem\",\n",
    "         \"net\",\"nfs\",\"numa\",\n",
    "         \"proc\",\"sysv_shm\",\"tmpfs\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and rename stats\n",
    "df = df.rename( columns={\"index\": \"Job Name\",\n",
    "                         \"intel_hsw\": \"Intel Haswell Processor (per core)\",\n",
    "                         \"ib\": \"Infiniband Usage\",\n",
    "                         #\"ib_sw\": \"Infiniband Usage\",\n",
    "                         #\"ib_ext\": \"Infiniband Usage\",\n",
    "                         \"llite\": \"Lustre Filesystem Usage (per mount)\",\n",
    "                         \"lnet\": \"Lustre Network Usage\",\n",
    "                         #\"mdc\": \"Lustre Network Usage\",\n",
    "                         #\"osc\": \"Lustre Filesystem Usage\",\n",
    "                         \"block\": \"Block Device Statistics (per device)\",\n",
    "                         \"cpu\": \"Scheduler Accounting (per CPU)\",\n",
    "                         \"mem\": \"Memory Usage\",\n",
    "                         \"net\": \"Network Device Usage (per device)\",\n",
    "                         \"nfs\": \"NFS System Usage\",\n",
    "                         \"numa\": \"NUMA Statistics (per socket)\",\n",
    "                         \"proc\": \"Process Specific Data\",\n",
    "                         \"sysv_shm\": \"System Shared Memory Segment Usage\",\n",
    "                         \"tmpfs\": \"RAM-Backed Filesystem Usage (per mount)\"\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "df = df.reindex(columns=[\"Job Name\",\n",
    "   \"Block Device Statistics (per device)\",\n",
    "   \"Intel Haswell Processor (per core)\",\n",
    "   \"Infiniband Usage\",\n",
    "   #\"Infiniband Usage\",\n",
    "   #\"Infiniband Usage\",\n",
    "   \"Lustre Filesystem Usage (per mount)\",\n",
    "   \"Lustre Network Usage\",\n",
    "   #\"Lustre Network Usage\",\n",
    "   #\"Lustre Filesystem Usage\",\n",
    "   \"Memory Usage\",\n",
    "   \"Network Device Usage (per device)\",\n",
    "   \"NFS System Usage\",\n",
    "   \"NUMA Statistics (per socket)\",\n",
    "   \"Process Specific Data\",\n",
    "   \"RAM-Backed Filesystem Usage (per mount)\",\n",
    "   \"Scheduler Accounting (per CPU)\",\n",
    "   \"System Shared Memory Segment Usage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy df to alter values\n",
    "means_df = df\n",
    "\n",
    "# compute avg of non-nan values\n",
    "for row in range(0, len(df.index)):\n",
    "    for col in range(0, len(df.columns)):\n",
    "        cell = df.iat[row,col]\n",
    "        if ( type(cell) == np.ndarray ):\n",
    "            means_df.iat[row,col] = np.mean(cell)\n",
    "\n",
    "means_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on columns with least non-nan values\n",
    "actual_df = pd.DataFrame(means_df[['Job Name', 'Intel Haswell Processor (per core)', \n",
    "                                   'Scheduler Accounting (per CPU)']].dropna())\n",
    "actual_df = actual_df.reset_index()[['Job Name', 'Intel Haswell Processor (per core)',\n",
    "                                     'Scheduler Accounting (per CPU)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for number of times stats collected\n",
    "# And column for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
